# ğŸ¦ Klasyfikacja GatunkÃ³w PtakÃ³w â€” Transfer Learning

Edukacyjny projekt klasyfikacji obrazÃ³w z wykorzystaniem **transfer learningu**
i modelu **EfficientNet-B0** pretrenowanego na ImageNet.

## ğŸ“‹ Opis projektu

Projekt rozpoznaje **30 gatunkÃ³w ptakÃ³w** na zdjÄ™ciach. Wykorzystuje technikÄ™
transfer learningu w dwÃ³ch fazach:

1. **Feature Extraction** â€” zamroÅ¼one warstwy bazowe, trening nowego klasyfikatora
2. **Fine-Tuning** â€” odmroÅ¼one warstwy, delikatne dostrojenie caÅ‚ego modelu

## ğŸ—‚ï¸ Struktura projektu

```
bird_classification/
â”œâ”€â”€ birds_train.py              # Skrypt treningowy (CLI)
â”œâ”€â”€ notebook.ipynb        # Jupyter Notebook (krok po kroku)
â”œâ”€â”€ requirements.txt      # ZaleÅ¼noÅ›ci Python
â”œâ”€â”€ README.md             # Ten plik
â”œâ”€â”€ data/                 # Dane (tworzone za pomocÄ… skryptu split_dataset.py)
â”‚   â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ val/
â”‚   â””â”€â”€ test/
â””â”€â”€ output/               # Wyniki (generowane automatycznie)
    â”œâ”€â”€ bird_classifier.pth
    â”œâ”€â”€ metadata.json
    â”œâ”€â”€ training_history.png
    â””â”€â”€ predictions/              â† Wyniki z predict.py
        â”œâ”€â”€ confusion_matrix.png
        â”œâ”€â”€ f1_per_class.png
        â”œâ”€â”€ error_examples.png
        â”œâ”€â”€ correct_examples.png
        â””â”€â”€ report.json
```

## ğŸš€ Szybki start

### 1. Instalacja

```bash
pip install -r requirements.txt
```

### 2. Przygotowanie danych

#### Opcja A: Dane demo (do testowania)
Skrypt automatycznie wygeneruje syntetyczne dane demo. Wystarczy uruchomiÄ‡ trening.

#### Opcja B: Prawdziwe dane (zalecane)
Pobierz dataset i umieÅ›Ä‡ w katalogu `data/`:

- **[CUB-200-2011](https://www.vision.caltech.edu/datasets/cub_200_2011/)** â€” 200 gatunkÃ³w, ~12k obrazÃ³w

Dane powinny mieÄ‡ strukturÄ™:
```
data/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ Gatunek_1/
â”‚   â”‚   â”œâ”€â”€ img001.jpg
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ Gatunek_2/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ val/
â””â”€â”€ test/
```
#### Skrypty do pomocy
Do projektu zostaÅ‚y doÅ‚Ä…czone skrypty `select_species.py` `split_dataset.py` pozwalajÄ…ce na Å‚atwiejsze kopiowanie obrazÃ³w z datasetu CUD-200-2011 do folderu data w sposÃ³b randomowy.
Wystarczy Å¼e do projektu wrzucisz folder CUD-200-2011/images z pobranej paczki (patrz Opcja B).

#### Ograniczenie od 1 do 200 gatunkÃ³w
JeÅ›li chcesz moÅ¼esz wybraÄ‡ dowolne ograniczenie sprawdzanych gatunkÃ³w np. 50 

```bash
python select_species.py --data_dir ./data --num_species 50
```
### 3. Trening

#### Skrypt Python:
```bash
python birds_train.py
```

#### Z parametrami:
```bash
python birds_train.py --num_epochs 30 --batch_size 64 --learning_rate 0.001
```

#### Jupyter Notebook:
```bash
jupyter notebook notebook.ipynb
```

## âš™ï¸ Hiperparametry

| Parametr | DomyÅ›lna wartoÅ›Ä‡ | Opis |
|----------|-----------------|------|
| `--num_epochs` | 20 | CaÅ‚kowita liczba epok |
| `--freeze_epochs` | 5 | Epoki z zamroÅ¼onymi warstwami |
| `--batch_size` | 16 | Rozmiar batcha |
| `--learning_rate` | 0.001 | LR dla feature extraction |
| `--fine_tune_lr` | 0.0001 | LR dla fine-tuningu |
| `--image_size` | 224 | Rozmiar obrazu wejÅ›ciowego |
| `--patience` | 5 | Early stopping patience |
| `--data_dir` | ./data | ÅšcieÅ¼ka do danych |
| `--output_dir` | ./output | ÅšcieÅ¼ka do wynikÃ³w |

## ğŸ“Š Techniki zastosowane

- **Transfer Learning** z EfficientNet-B0 (ImageNet)
- **Dwufazowy trening**: Feature Extraction â†’ Fine-Tuning
- **Augmentacja danych**: RandomCrop, Flip, Rotation, ColorJitter
- **Early Stopping** â€” zapobiega przeuczeniu
- **Learning Rate Scheduling** â€” ReduceLROnPlateau
- **Differential Learning Rates** â€” rÃ³Å¼ne LR dla rÃ³Å¼nych warstw

## ğŸ”® Predykcja na nowym zdjÄ™ciu

```python
from train import predict_image, create_data_transforms
import torch
from torchvision import models
import torch.nn as nn

# ZaÅ‚aduj model
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
checkpoint = torch.load('output/bird_classifier.pth', map_location=device)

model = models.efficientnet_b0(weights=None)
nf = model.classifier[1].in_features
model.classifier = nn.Sequential(
    nn.Dropout(0.3), nn.Linear(nf, 512), nn.ReLU(),
    nn.Dropout(0.2), nn.Linear(512, checkpoint['num_classes']))
model.load_state_dict(checkpoint['model_state_dict'])
model = model.to(device)
model.eval()

# Predykcja
transforms = create_data_transforms()
predicted, confidence, top5 = predict_image(
    model, 'path/to/bird.jpg', checkpoint['class_names'], transforms, device)

print(f'Gatunek: {predicted} ({confidence:.1%})')
```

## ğŸ“– Zasoby edukacyjne

- [PyTorch Transfer Learning Tutorial](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)
- [EfficientNet Paper (Tan & Le, 2019)](https://arxiv.org/abs/1905.11946)
- [CS231n: Transfer Learning](https://cs231n.github.io/transfer-learning/)


